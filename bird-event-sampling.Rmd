---
title: "Exploring NEON Bird abundance data"
output: github_document
---

## Warm-up: exploring the data schema of the NEON sampling routine

```{r setup, message = FALSE}

library(lubridate)
library(tidyverse)

library(contenturi) # remotes::install_github("cboettig/contenturi@names")
library(neonstore)


```


We'll use a cached copy of the bird data (see `import_data.Rmd` for import from NEON).

```{r}

stacked_products <- function(dpID){
  neonstore::neon_registry() %>% 
      readr::read_csv() %>%
      dplyr::filter(product == paste0("stacked-", dpID)) %>% 
      dplyr::select(id, name) %>% 
      dplyr::distinct()
}
  
df <- stacked_products("DP1.10003.001")


```

```{r}
## We'll access the data by content identifier for data reproducibility
#f <- contenturi::resolve("hash://sha256/758f1d665d5a25f48e9fa52f3eda7bc320003187c70a3c12a8bfcd13824be3af")
 brd_countdata <- contenturi::retrieve(
    "hash://sha256/3544e9345cc9ff9e235ff49e2d446dfea1ce5fb2be2c82c66f4e58516bf8a3bd")

#bird <- readRDS(f) 
brd_df <- read_csv(brd_countdata)
```





Let's find a relatively complicated event
```{r}
exciting_event <- brd_df %>% count(eventID, sort=TRUE) %>% head(1) %>% pull(eventID) 
```


By definition, these occur at the same location: (siteID, plotID, pointID), and time (startDate).  So let's drop the info that's shared across all (65) entries in this event `eventID ("LAJA_001.21.2018-05-26T07:01-04:00[America/Puerto_Rico]")`

```{r}
df <- brd_df %>%  
  filter(eventID == exciting_event) %>% 
  select(-siteID, -plotID, -pointID, -eventID, -uid,
         -namedLocation, -domainID, -plotType,
         -startDate, -publicationDate)
df %>% head()
```


Let's focus on just the most commonly seen of the 18 species observed in this event (looks to be `"Tyrannus dominicensis"`).  Again, we'll drop the fields that shared across all entries

```{r}
common <- df %>% count(scientificName, sort = TRUE) %>% head(1) %>% pull(scientificName)
kingbird <- df %>% filter(scientificName == common) %>% select(-taxonID, -scientificName, -taxonRank, -vernacularName, -family)
kingbird
```

Looks like we have 2 observers (IRC and EFN), with IRC identifying by `singing` and EFN by `visual`. We also get observations by minute of the six-minute interval

```{r}
ex <- kingbird %>% 
  select(pointCountMinute, clusterSize, observerDistance, 
         detectionMethod, identifiedBy, visualConfirmation) %>% 
  arrange(pointCountMinute)

head(ex)

```

How shall we estimate a species density from this data?  Apparently, research interpets this question through the lens of "detection probability" as if there were a "true", uniform density of birds over the landscape (which we seek to estimate) but he probability that an observer sees a bird is a function only of the distance to the observer and the unknown density.  (Guessing social behavior of flocks is going to be hard to include?)

Of course our sampling probability may differ across species and location-specific variables such as plotType / domainID, as well as some temporal dependence; presumably a generic model will allow us to account for these parametrically to borrow power across these events.  We will revisit these issues after considering what a density estimate looks like when those differences across space/time/species are held fixed. 


----------

# Using the `Distance` package on NEON observations


Of course we want to leverage prior art in this analysis as well.  One line of analysis is the class of distance based methods, e.g. [Buckland et al](https://doi.org/10.1007/978-3-319-19219-2 "Distance Sampling: Methods and Applications").  This group appears to have a substantial suite of [associated software](https://github.com/DistanceDevelopment/Distance), including the [`Distance` R package](https://cran.r-project.org/web/packages/Distance/) described [in JSS](https://doi.org/10.18637/jss.v089.i01). 



<!--
Perhaps these methods could be applied in an appropriate pipeline to create a higher-level data product summarizing abundance efforts, which would be the focus of further analysis and any forecasting predictions.

I am also curious if it is reasonable to forecast the 'observed data' directly without invoking the concept of abundance, and if so, what it would mean.  
-->


```{r}
library(Distance)

## Defines a data schema: see `?flatfile`
# ?flatfile
```

In the `Distance` schema, columns are: 

`distance`: 	observed distance to object
`Sample.Label`: 	Identifier for the sample (transect id)
`Effort`: 	effort for this transect (e.g. line transect length or number of times point transect was visited)
`Region.Label`: 	label for a given stratum (see below)
`Area`: 	area of the strata  
  
How do these compare to the NEON sample protocol schema?  `distance` is clearly `observerDistance`.  I believe `Region.Label` corresponds to `PlotID`,
though it could also be considered as `SiteID`?  `Area` is area of the region, though I'll need to go beyond the package documentation to determine where the heck Area figures into the calculation (a separate notion of area already being implicit in the radial observation distance function). 
It's a bit buried, but the schema assumes `size` is clusterSize.  

`SampleID` is probably `eventID`, or `pointID` -- the schema seems to use `Effort` to count "the number of times a point was revisited", and does not seem to have a notion of the length/duration of the visit, but no doubt assumes those are standardized.  Our points are indeed revisted, 

```{r}
bird_ds <- brd_df %>% mutate(pointID = paste(plotID, pointID, sep="-")) # easier when pointID is unique
effort <- bird_ds %>% select(pointID,startDate) %>% distinct() %>% count(pointID)

```


Let's take a look at how detection probability might depend on distance:

```{r}
bird_ds %>% count(family, sort = TRUE) %>% head() %>% na.omit() -> common
common

bird_ds %>% inner_join(common) %>% ggplot(aes(observerDistance)) + 
  geom_histogram() + facet_wrap(~family, scales = "free_y")
```

Those distances at 1km sound suspect, probably a rounding effect.

```{r}
bird_ds %>% inner_join(common) %>% 
  filter(observerDistance < 900) %>% 
  ggplot(aes(observerDistance)) + 
  geom_histogram() + facet_wrap(~family, scales = "free_y")
```

What's `Distance` doing with `Area`?  Looks like this is just used to turn denities into abundances.  For the moment we will take `Area = 1` then and treat our estimates as densities.  (`brd_perpoint` table gives lat-long coordinates of the sample points, we could attempt to draw enclosing polygons around points in a plot, but that seems like a potentially poor estimate of plot area.  More importantly, it is not clear that the count in the plot area is of any intrinsic interest). (Perhaps Region.Label is only used to associate regional areas, it's not clear if the methods are allowing for the density estimate function to actually differ across region.  Of course this is something we can manually do by grouping by plotID or siteID)



  
```{r}
ds_data <- bird_ds %>% 
  left_join(rename(effort, Effort = n), by = "pointID") %>%
  select(family, 
       distance = observerDistance, Sample.Label = eventID, 
       Region.Label = plotID, size = clusterSize) %>% 
  mutate(Area = 1) 


```




```{r}
topbird <- common %>% pull(family) 
```


A single example: 

```{r}
ex <- ds_data %>% filter(family %in% topbird[[1]]) %>% as.data.frame(stringsAsFactors = TRUE)
m <- ds(ex, transect = "point")

```

Some helper extraction methods (becuase it's great when all the summary statistics are buried in print methods)

```{r}
 estimate_table <- function(abund) {
  abund_summary <- summary(abund)
  x <- abund_summary$ds
  if(!is.null(x$Nhat)){
    parameters=data.frame(Estimate=c(x$average.p,x$Nhat))
    row.names(parameters)=c("Average p", "N in covered region")
    if(!is.null(x$average.p.se)){
      parameters$SE=c(x$average.p.se,x$Nhat.se)
      parameters$CV=parameters$SE/parameters$Estimate
    }
  }else{
    parameters=data.frame(Estimate=c(x$average.p))
    row.names(parameters)=c("Average p")
    if(!is.null(x$average.p.se)){
      parameters$SE=c(x$average.p.se)
      parameters$CV=parameters$SE/parameters$Estimate
    }
  }
parameters
}
```

And now we can estimate density and abundance:

```{r}
estimate_table(m)
```


```{r error=FALSE}
ex <- ds_data %>% filter(family %in% topbird) %>% as.data.frame(stringsAsFactors = TRUE)

abund <- ex %>% group_by(family) %>% 
  dplyr::group_modify( function(df, ...){
    m <- ds(as.data.frame(df), transect = "point")
    out <- estimate_table(m)
    out <- tibble::rownames_to_column(out)
    out
  }, keep = TRUE)

```

```{r}
abund
```

