---
title: "Beetles"
output: 
  github_document:
    df_print: tibble
---

```{r setup,message=FALSE}
library(lubridate)
library(tidyverse)
```


```{r}
neonstore::neon_download("DP1.10022.001")
bet_sorting <- neonstore::neon_read("bet_sorting")
# bet_sorting <- read_csv("../data/bet_sorting-basic.csv") # Ben's hack
sites <- neonstore::neon_sites() 


```


```{r}
bet_ts <- bet_sorting %>% 
  select(collectDate, siteID, domainID, scientificName, individualCount) %>%
  mutate(month = format(collectDate, "%Y-%m")) %>% 
  mutate(month = as.Date(paste(month, "01", sep="-"))) %>%
  group_by(scientificName, month, siteID, domainID) %>%
  summarize(count = sum(individualCount, na.rm = TRUE)) %>%
  ungroup()

bet_samples <- bet_sorting %>% 
  select(collectDate, siteID, plotID, domainID, trapID, scientificName, individualCount )%>%
  mutate(month = format(collectDate, "%Y-%m")) %>% 
  mutate(month = as.Date(paste(month, "01", sep="-"))) %>%
  group_by(scientificName, month, siteID, domainID)

```

## Counts

First let's take a quick look at the raw counts data.  This is less meaningful than abundance,
since we would need to account for detection probability, and effort is not entirely constant over
time or necessarily equal across sites.  Details of the estimation of beetle density will need to
take into account the specifics of the pitfall sampling design.  For now, let's consider only the
raw counts, which are much simpler to work with and free from assumptions required to estimate abundance:


To start, here is cumulative counts across all beetles: shows an increase which is no doubt connected 
to increased sampling effort as sites come online, along with an obvious seasonal 
pattern...


```{r}
totals <- bet_ts %>% 
  group_by(month) %>%
  summarize(count = sum(count, na.rm = TRUE)) %>%
  ungroup()

totals %>% ggplot(aes(month, count)) + geom_line() + geom_point()
```


```{r}
bysite <- bet_ts %>% 
  group_by(month, siteID, domainID) %>%
  summarize(count = sum(count, na.rm = TRUE)) %>%
  ungroup()

domains <- sites %>% select(domainCode, domainName) %>% distinct()
bet_domain <- bysite %>% left_join(domains, by = c(domainID = "domainCode"))
```

```{r fig.width=10, fig.height=20}

bet_domain %>% ggplot(aes(month, count)) + geom_line() + geom_point() + 
  facet_wrap(~domainName, ncol = 3, scale = "free_y")
```



-------------------------------------


```{r}
## now the fun starts
library(nimbleEcology)
```

## Estimating abundance

> Ground beetles are sampled using pitfall traps (16 oz deli containers filled with 150 or 250 mL of propylene glycol). Four traps are deployed in each of 10 plots at each terrestrial NEON site (40 traps per site), with traps arrayed approximately 20 meters from the center of the plot in each of the four cardinal directions. Sampling occurs biweekly throughout the growing season (when temperatures are above 4 degrees C).


--------------


## Ben's try


```{r}
library(neonstore)
bet_sorting <- neon_read("bet_sorting", dir = "/home/shared-data/neonstore/")
bet_raw <- neon_read("bet_fielddata-basic", dir = "/home/shared-data/neonstore/")
```

I want a list of each trap x plot x site combination.

```{r}
all_locs <- bet_raw %>% 
            select(trapID, plotID, siteID) %>% 
            distinct() %>% 
            arrange(plotID)
```


Now when I get data for a specific date, I'll associate it with the list stored
in `all_locs` and put in 0s for any site that didn't have species collected
on that date.

I'm going to start by taking a look at just one site & one species.


```{r}
bet_sorting %>% 
  filter(siteID == "ORNL") %>% 
  count(scientificName, sort=TRUE)


prep_dat_onesitedate <- function(site, date, species,
                                 bet_sorting, all_locs) {
  spec_site_dat <- bet_sorting %>% 
    filter(scientificName == species, 
           siteID == site,
           collectDate == date) %>% 
    select(siteID, plotID, trapID, collectDate, individualCount) %>% 
    arrange(plotID, trapID) %>% 
    distinct()
  
  all_locs_this_site <- all_locs %>% 
    filter(siteID == site)
    
  all_loc_data <- left_join(all_locs_this_site, spec_site_dat,
                            by = c("siteID", "plotID", "trapID"))
  all_loc_data$collectDate <- date
  all_loc_data$individualCount[is.na(all_loc_data$individualCount)] <- 0
  
  all_loc_data <- all_loc_data %>% 
    mutate(plot_int = as.numeric(as.factor(paste0(siteID, plotID, collectDate)))) %>% 
    arrange(plot_int)    
  
  return(all_loc_data)
}

# The following code gets me the start and end vectors of the data each plot
get_start_end <- function(model_data) {
  start_vec <- numeric(max(model_data$plot_int))
  end_vec <- numeric(max(model_data$plot_int))
  
  for (i in 1:length(start_vec)) {
    start_vec[i] <- min(which(model_data$plot_int == i))
    end_vec[i] <- max(which(model_data$plot_int == i))
  }
  return(list(start = start_vec, end = end_vec))
}


```

Apply the functions I wrote to a selected site and date.

```{r}
model_data <- prep_dat_onesitedate(site = "ORNL", date = as.Date("2014-06-03"),
                                   species = "Cyclotrachelus fucatus",
                                   bet_sorting, all_locs)
start_end_vecs <- get_start_end(model_data)
```


Now I put together a nimbleModel for these data.

```{r}
nmix_onesite_code <- nimbleCode({
  for (plot in 1:nplot) {
    # Each set 
    y[start[plot]:end[plot]] ~ 
        dNmixture_s(lambda = lambda,
                    prob = prob,
                    Nmin = 0,
                    Nmax = 800,
                    len = 1 + end[plot] - start [plot])
  }
  
  lambda ~ dunif(0, 10000)
  prob ~ dunif(0, 1)
})

onesite_model <- nimbleModel(nmix_onesite_code,
                             constants = list(start = start_end_vecs$start,
                                              end = start_end_vecs$start,
                                              nplot = max(model_dat$plot_int)),
                             data = list(y = model_dat$individualCount),
                             inits = list(prob = 0.5, 
                                          lambda = mean(spec_site_dat$individualCount) * 2))
```

With this very simple model, we could use MCMC or MLE. I'll demo an easy MCMC
workflow so that we can use it even as the model gets more complicated.


```{r}
onesite_MCMC <- buildMCMC(onesite_model)

Cmodel <- compileNimble(onesite_model)
CMCMC <- compileNimble(onesite_MCMC)

```

```{r}
samples <- runMCMC(CMCMC, niter = 50000, nburnin = 5000)

plot(samples[,1], type = "l")
plot(density(samples[,1]))

plot(samples[,2], type = "l")
plot(density(samples[,1]))
```

The mixing looks bad because the model is close to unidentifiable with constant p
and constant lambda, so I expect that as we increase model complexity (to a
degree) things will improve.

### Ben's try #2: multiple dates

I'll check this by using more than one month. I'll put month as a covariate on
abundance and plot as a random effect on detection probability.

```{r}
# Grab the data. Apply the original function across many dates, then 
dates_needed <- bet_sorting %>% 
                filter(siteID == "ORNL") %>% 
                select(collectDate) %>%
                unique()

model_data_list <- lapply(dates_needed$collectDate,
                          prep_dat_onesitedate,
                          site = "ORNL", species = "Cyclotrachelus fucatus",
                          bet_sorting = bet_sorting,
                          all_locs = all_locs)
model_data_ts <- bind_rows(model_data_list)
model_data_ts <- model_data_ts %>% 
  mutate(plot_int = as.numeric(as.factor(paste0(siteID,
                                                plotID,
                                                collectDate)))) %>% 
  arrange(plot_int)

start_end_vecs_ts <- get_start_end(model_data_ts)
```




```{r}
nmix_spacetime_code <- nimbleCode({
  
  # for each spacetime plot...
  for (st in 1:nspacetime) {
    
    # Mean abundance is a log-linked linear combo with which month it is
    log(lambda[st]) <- abund_int + beta_month * month[st]
    
    # Prob of detection is a logit-linked random effect on which geog plot it is
    logit(prob[st]) <- prob_int + pranef[geoplot[st]]
    
    # Each set 
    y[start[st]:end[st]] ~ 
        dNmixture_s(lambda = lambda[st],
                    prob = prob[st],
                    Nmin = 0,
                    Nmax = 1000,
                    len = 1 + end[st] - start[st])
  }
  
  
  # Priors
  beta_month ~ dnorm(0, sd = 1000)
  abund_int ~ dnorm(0, sd = 1000)
  prob_int ~ dnorm(0, sd = 1000)
  pranef_sd ~ dunif(0, 100)
  for (i in 1:ngeoplots) {
    pranef[i] ~ dnorm(0, sd = pranef_sd)
  }

  
})

spacetime_model <- nimbleModel(nmix_spacetime_code,
                             constants = list(start = start_vec,
                                              end = end_vec,
                                              nspacetime = length(start_vec),
                                              ngeoplots = length(unique(mod_dat$plotID)),
                                              month = as.numeric(scale(month(mod_dat$month))),
                                              geoplot = as.numeric(as.factor(mod_dat$plotID))
                                              ),
                             data = list(y = mod_dat$individualCount),
                             inits = list(prob_int = 0, 
                                          pranef_sd = 1,
                                          pranef = rnorm(length(unique(mod_dat$plotID)), 0, 1),
                                          abund_int = mean(mod_dat$individualCount) * 2,
                                          beta_month = 0))
```
Back to MCMC.



```{r}
spacetime_MCMC <- buildMCMC(spacetime_model)

Cmodel <- compileNimble(spacetime_model)
CMCMC <- compileNimble(spacetime_MCMC)

```


```{r}
samples <- runMCMC(CMCMC, niter = 5000, nburnin = 1000)
for (i in 1:ncol(samples)) {
  plot(samples[,i], type = "l", main = colnames(samples)[i])
  plot(density(samples[,i]), main = colnames(samples)[i])
}
``` 

This is still mixing poorly but probably isn't worth worrying too much about at this step.

Our predicted values of interest:

```{r}
# Mean expectation of abundance
exp(mean(samples[,"abund_int"]))
# Linear relationship btw month abundance on the log scale (probably not a great model)
mean(samples[,"beta_month"])
# mean expectation of detection rate
expit(mean(samples[, "prob_int"]))
# How much does detection vary from plot to plot, on the logit scale?
mean(samples[, "pranef_sd"])
```

